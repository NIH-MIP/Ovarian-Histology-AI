{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4f436f8-0171-4f26-9cfd-2d7490d4d035",
   "metadata": {},
   "source": [
    "# <font size=\"6\">Object Detection Inference on ANY slide (all section of tissue will be used)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8004477f-0fde-46c6-9b5f-de4e3cb3da51",
   "metadata": {},
   "source": [
    "### <font size=\"5\">Load model and params</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44c12cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from icevision.all import *\n",
    "from icevision.models import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce2d29c7-78cf-41ff-b80c-11485057385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5828a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize paths and files to run inference\n",
    "checkpoint_path = './models/torchvision_fasterRCNN_10x.pth'\n",
    "json_dir = './output'\n",
    "slide_dir = './input/'\n",
    "slide_list = ['17133893']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7c8a4f8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: models/torchvision_fasterRCNN_10x.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 21:10:42,450 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet101'}\n",
      "2025-09-22 21:10:42,451 - mmcv - INFO - load model from: torchvision://resnet101\n",
      "2025-09-22 21:10:42,451 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet101\n",
      "2025-09-22 21:10:42,615 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2025-09-22 21:10:42,650 - mmcv - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2025-09-22 21:10:42,669 - mmcv - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
      "2025-09-22 21:10:42,674 - mmcv - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
      "2025-09-22 21:10:43,104 - mmcv - INFO - \n",
      "backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,105 - mmcv - INFO - \n",
      "backbone.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,105 - mmcv - INFO - \n",
      "backbone.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,106 - mmcv - INFO - \n",
      "backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,106 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,106 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,106 - mmcv - INFO - \n",
      "backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,107 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,107 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,108 - mmcv - INFO - \n",
      "backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,108 - mmcv - INFO - \n",
      "backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,108 - mmcv - INFO - \n",
      "backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,108 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,109 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,109 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,109 - mmcv - INFO - \n",
      "backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,110 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,110 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,110 - mmcv - INFO - \n",
      "backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,111 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,111 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,111 - mmcv - INFO - \n",
      "backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,111 - mmcv - INFO - \n",
      "backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,112 - mmcv - INFO - \n",
      "backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,112 - mmcv - INFO - \n",
      "backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,112 - mmcv - INFO - \n",
      "backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,112 - mmcv - INFO - \n",
      "backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,113 - mmcv - INFO - \n",
      "backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,113 - mmcv - INFO - \n",
      "backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,114 - mmcv - INFO - \n",
      "backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,114 - mmcv - INFO - \n",
      "backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,114 - mmcv - INFO - \n",
      "backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,114 - mmcv - INFO - \n",
      "backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,115 - mmcv - INFO - \n",
      "backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,115 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,116 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,116 - mmcv - INFO - \n",
      "backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,116 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,116 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,117 - mmcv - INFO - \n",
      "backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,117 - mmcv - INFO - \n",
      "backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,117 - mmcv - INFO - \n",
      "backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,117 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,118 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,118 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,119 - mmcv - INFO - \n",
      "backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,119 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,119 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 21:10:43,119 - mmcv - INFO - \n",
      "backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,120 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,120 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,120 - mmcv - INFO - \n",
      "backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,121 - mmcv - INFO - \n",
      "backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,121 - mmcv - INFO - \n",
      "backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,121 - mmcv - INFO - \n",
      "backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,121 - mmcv - INFO - \n",
      "backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,122 - mmcv - INFO - \n",
      "backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,122 - mmcv - INFO - \n",
      "backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,122 - mmcv - INFO - \n",
      "backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,123 - mmcv - INFO - \n",
      "backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,123 - mmcv - INFO - \n",
      "backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,123 - mmcv - INFO - \n",
      "backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,124 - mmcv - INFO - \n",
      "backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,124 - mmcv - INFO - \n",
      "backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,124 - mmcv - INFO - \n",
      "backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,124 - mmcv - INFO - \n",
      "backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,125 - mmcv - INFO - \n",
      "backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,125 - mmcv - INFO - \n",
      "backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,125 - mmcv - INFO - \n",
      "backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,126 - mmcv - INFO - \n",
      "backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,126 - mmcv - INFO - \n",
      "backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,126 - mmcv - INFO - \n",
      "backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,127 - mmcv - INFO - \n",
      "backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,127 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,127 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,127 - mmcv - INFO - \n",
      "backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,128 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,128 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,128 - mmcv - INFO - \n",
      "backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,129 - mmcv - INFO - \n",
      "backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,129 - mmcv - INFO - \n",
      "backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,129 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,130 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,130 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,130 - mmcv - INFO - \n",
      "backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,130 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,131 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,131 - mmcv - INFO - \n",
      "backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,132 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,132 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,132 - mmcv - INFO - \n",
      "backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,132 - mmcv - INFO - \n",
      "backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,133 - mmcv - INFO - \n",
      "backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,133 - mmcv - INFO - \n",
      "backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,133 - mmcv - INFO - \n",
      "backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,134 - mmcv - INFO - \n",
      "backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,134 - mmcv - INFO - \n",
      "backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,134 - mmcv - INFO - \n",
      "backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,134 - mmcv - INFO - \n",
      "backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,135 - mmcv - INFO - \n",
      "backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,135 - mmcv - INFO - \n",
      "backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,135 - mmcv - INFO - \n",
      "backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,135 - mmcv - INFO - \n",
      "backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 21:10:43,136 - mmcv - INFO - \n",
      "backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,136 - mmcv - INFO - \n",
      "backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,137 - mmcv - INFO - \n",
      "backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,137 - mmcv - INFO - \n",
      "backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,137 - mmcv - INFO - \n",
      "backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,138 - mmcv - INFO - \n",
      "backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,138 - mmcv - INFO - \n",
      "backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,138 - mmcv - INFO - \n",
      "backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,138 - mmcv - INFO - \n",
      "backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,139 - mmcv - INFO - \n",
      "backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,139 - mmcv - INFO - \n",
      "backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,139 - mmcv - INFO - \n",
      "backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,139 - mmcv - INFO - \n",
      "backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,140 - mmcv - INFO - \n",
      "backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,140 - mmcv - INFO - \n",
      "backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,140 - mmcv - INFO - \n",
      "backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,140 - mmcv - INFO - \n",
      "backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,141 - mmcv - INFO - \n",
      "backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,141 - mmcv - INFO - \n",
      "backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,141 - mmcv - INFO - \n",
      "backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,141 - mmcv - INFO - \n",
      "backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,142 - mmcv - INFO - \n",
      "backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,142 - mmcv - INFO - \n",
      "backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,142 - mmcv - INFO - \n",
      "backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,142 - mmcv - INFO - \n",
      "backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,143 - mmcv - INFO - \n",
      "backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,143 - mmcv - INFO - \n",
      "backbone.layer3.6.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,143 - mmcv - INFO - \n",
      "backbone.layer3.6.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,143 - mmcv - INFO - \n",
      "backbone.layer3.6.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,143 - mmcv - INFO - \n",
      "backbone.layer3.6.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,144 - mmcv - INFO - \n",
      "backbone.layer3.6.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,144 - mmcv - INFO - \n",
      "backbone.layer3.6.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,144 - mmcv - INFO - \n",
      "backbone.layer3.6.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,144 - mmcv - INFO - \n",
      "backbone.layer3.6.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,145 - mmcv - INFO - \n",
      "backbone.layer3.6.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,145 - mmcv - INFO - \n",
      "backbone.layer3.7.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,145 - mmcv - INFO - \n",
      "backbone.layer3.7.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,145 - mmcv - INFO - \n",
      "backbone.layer3.7.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,146 - mmcv - INFO - \n",
      "backbone.layer3.7.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,146 - mmcv - INFO - \n",
      "backbone.layer3.7.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,146 - mmcv - INFO - \n",
      "backbone.layer3.7.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,146 - mmcv - INFO - \n",
      "backbone.layer3.7.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,146 - mmcv - INFO - \n",
      "backbone.layer3.7.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,147 - mmcv - INFO - \n",
      "backbone.layer3.7.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,147 - mmcv - INFO - \n",
      "backbone.layer3.8.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,147 - mmcv - INFO - \n",
      "backbone.layer3.8.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,147 - mmcv - INFO - \n",
      "backbone.layer3.8.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,148 - mmcv - INFO - \n",
      "backbone.layer3.8.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,148 - mmcv - INFO - \n",
      "backbone.layer3.8.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,148 - mmcv - INFO - \n",
      "backbone.layer3.8.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,148 - mmcv - INFO - \n",
      "backbone.layer3.8.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,149 - mmcv - INFO - \n",
      "backbone.layer3.8.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,149 - mmcv - INFO - \n",
      "backbone.layer3.8.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,149 - mmcv - INFO - \n",
      "backbone.layer3.9.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,149 - mmcv - INFO - \n",
      "backbone.layer3.9.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 21:10:43,153 - mmcv - INFO - \n",
      "backbone.layer3.9.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,153 - mmcv - INFO - \n",
      "backbone.layer3.9.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,153 - mmcv - INFO - \n",
      "backbone.layer3.9.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,154 - mmcv - INFO - \n",
      "backbone.layer3.9.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,154 - mmcv - INFO - \n",
      "backbone.layer3.9.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,154 - mmcv - INFO - \n",
      "backbone.layer3.9.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,154 - mmcv - INFO - \n",
      "backbone.layer3.9.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,155 - mmcv - INFO - \n",
      "backbone.layer3.10.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,155 - mmcv - INFO - \n",
      "backbone.layer3.10.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,155 - mmcv - INFO - \n",
      "backbone.layer3.10.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,155 - mmcv - INFO - \n",
      "backbone.layer3.10.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,156 - mmcv - INFO - \n",
      "backbone.layer3.10.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,156 - mmcv - INFO - \n",
      "backbone.layer3.10.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,156 - mmcv - INFO - \n",
      "backbone.layer3.10.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,156 - mmcv - INFO - \n",
      "backbone.layer3.10.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,156 - mmcv - INFO - \n",
      "backbone.layer3.10.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,157 - mmcv - INFO - \n",
      "backbone.layer3.11.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,157 - mmcv - INFO - \n",
      "backbone.layer3.11.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,157 - mmcv - INFO - \n",
      "backbone.layer3.11.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,157 - mmcv - INFO - \n",
      "backbone.layer3.11.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,158 - mmcv - INFO - \n",
      "backbone.layer3.11.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,158 - mmcv - INFO - \n",
      "backbone.layer3.11.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,158 - mmcv - INFO - \n",
      "backbone.layer3.11.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,158 - mmcv - INFO - \n",
      "backbone.layer3.11.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,159 - mmcv - INFO - \n",
      "backbone.layer3.11.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,159 - mmcv - INFO - \n",
      "backbone.layer3.12.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,159 - mmcv - INFO - \n",
      "backbone.layer3.12.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,161 - mmcv - INFO - \n",
      "backbone.layer3.12.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,161 - mmcv - INFO - \n",
      "backbone.layer3.12.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,161 - mmcv - INFO - \n",
      "backbone.layer3.12.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,162 - mmcv - INFO - \n",
      "backbone.layer3.12.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,162 - mmcv - INFO - \n",
      "backbone.layer3.12.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,162 - mmcv - INFO - \n",
      "backbone.layer3.12.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,162 - mmcv - INFO - \n",
      "backbone.layer3.12.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,163 - mmcv - INFO - \n",
      "backbone.layer3.13.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,163 - mmcv - INFO - \n",
      "backbone.layer3.13.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,163 - mmcv - INFO - \n",
      "backbone.layer3.13.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,163 - mmcv - INFO - \n",
      "backbone.layer3.13.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,164 - mmcv - INFO - \n",
      "backbone.layer3.13.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,164 - mmcv - INFO - \n",
      "backbone.layer3.13.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,164 - mmcv - INFO - \n",
      "backbone.layer3.13.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,164 - mmcv - INFO - \n",
      "backbone.layer3.13.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,165 - mmcv - INFO - \n",
      "backbone.layer3.13.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,165 - mmcv - INFO - \n",
      "backbone.layer3.14.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,165 - mmcv - INFO - \n",
      "backbone.layer3.14.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,165 - mmcv - INFO - \n",
      "backbone.layer3.14.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,165 - mmcv - INFO - \n",
      "backbone.layer3.14.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,166 - mmcv - INFO - \n",
      "backbone.layer3.14.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,166 - mmcv - INFO - \n",
      "backbone.layer3.14.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,166 - mmcv - INFO - \n",
      "backbone.layer3.14.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,166 - mmcv - INFO - \n",
      "backbone.layer3.14.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,167 - mmcv - INFO - \n",
      "backbone.layer3.14.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,167 - mmcv - INFO - \n",
      "backbone.layer3.15.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,167 - mmcv - INFO - \n",
      "backbone.layer3.15.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,167 - mmcv - INFO - \n",
      "backbone.layer3.15.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 21:10:43,168 - mmcv - INFO - \n",
      "backbone.layer3.15.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,168 - mmcv - INFO - \n",
      "backbone.layer3.15.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,168 - mmcv - INFO - \n",
      "backbone.layer3.15.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,168 - mmcv - INFO - \n",
      "backbone.layer3.15.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,168 - mmcv - INFO - \n",
      "backbone.layer3.15.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,169 - mmcv - INFO - \n",
      "backbone.layer3.15.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,169 - mmcv - INFO - \n",
      "backbone.layer3.16.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,169 - mmcv - INFO - \n",
      "backbone.layer3.16.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,169 - mmcv - INFO - \n",
      "backbone.layer3.16.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,170 - mmcv - INFO - \n",
      "backbone.layer3.16.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,170 - mmcv - INFO - \n",
      "backbone.layer3.16.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,170 - mmcv - INFO - \n",
      "backbone.layer3.16.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,170 - mmcv - INFO - \n",
      "backbone.layer3.16.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,171 - mmcv - INFO - \n",
      "backbone.layer3.16.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,171 - mmcv - INFO - \n",
      "backbone.layer3.16.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,171 - mmcv - INFO - \n",
      "backbone.layer3.17.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,171 - mmcv - INFO - \n",
      "backbone.layer3.17.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,172 - mmcv - INFO - \n",
      "backbone.layer3.17.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,172 - mmcv - INFO - \n",
      "backbone.layer3.17.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,172 - mmcv - INFO - \n",
      "backbone.layer3.17.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,172 - mmcv - INFO - \n",
      "backbone.layer3.17.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,173 - mmcv - INFO - \n",
      "backbone.layer3.17.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,173 - mmcv - INFO - \n",
      "backbone.layer3.17.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,173 - mmcv - INFO - \n",
      "backbone.layer3.17.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,173 - mmcv - INFO - \n",
      "backbone.layer3.18.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,173 - mmcv - INFO - \n",
      "backbone.layer3.18.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,174 - mmcv - INFO - \n",
      "backbone.layer3.18.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,174 - mmcv - INFO - \n",
      "backbone.layer3.18.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,174 - mmcv - INFO - \n",
      "backbone.layer3.18.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,174 - mmcv - INFO - \n",
      "backbone.layer3.18.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,175 - mmcv - INFO - \n",
      "backbone.layer3.18.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,175 - mmcv - INFO - \n",
      "backbone.layer3.18.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,175 - mmcv - INFO - \n",
      "backbone.layer3.18.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,175 - mmcv - INFO - \n",
      "backbone.layer3.19.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,176 - mmcv - INFO - \n",
      "backbone.layer3.19.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,176 - mmcv - INFO - \n",
      "backbone.layer3.19.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,180 - mmcv - INFO - \n",
      "backbone.layer3.19.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,181 - mmcv - INFO - \n",
      "backbone.layer3.19.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,181 - mmcv - INFO - \n",
      "backbone.layer3.19.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,181 - mmcv - INFO - \n",
      "backbone.layer3.19.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,181 - mmcv - INFO - \n",
      "backbone.layer3.19.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,182 - mmcv - INFO - \n",
      "backbone.layer3.19.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,182 - mmcv - INFO - \n",
      "backbone.layer3.20.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,182 - mmcv - INFO - \n",
      "backbone.layer3.20.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,182 - mmcv - INFO - \n",
      "backbone.layer3.20.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,183 - mmcv - INFO - \n",
      "backbone.layer3.20.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,183 - mmcv - INFO - \n",
      "backbone.layer3.20.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,183 - mmcv - INFO - \n",
      "backbone.layer3.20.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,183 - mmcv - INFO - \n",
      "backbone.layer3.20.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,183 - mmcv - INFO - \n",
      "backbone.layer3.20.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,184 - mmcv - INFO - \n",
      "backbone.layer3.20.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,184 - mmcv - INFO - \n",
      "backbone.layer3.21.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,184 - mmcv - INFO - \n",
      "backbone.layer3.21.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,184 - mmcv - INFO - \n",
      "backbone.layer3.21.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,185 - mmcv - INFO - \n",
      "backbone.layer3.21.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 21:10:43,185 - mmcv - INFO - \n",
      "backbone.layer3.21.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,185 - mmcv - INFO - \n",
      "backbone.layer3.21.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,185 - mmcv - INFO - \n",
      "backbone.layer3.21.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,186 - mmcv - INFO - \n",
      "backbone.layer3.21.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,186 - mmcv - INFO - \n",
      "backbone.layer3.21.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,186 - mmcv - INFO - \n",
      "backbone.layer3.22.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,186 - mmcv - INFO - \n",
      "backbone.layer3.22.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,186 - mmcv - INFO - \n",
      "backbone.layer3.22.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,187 - mmcv - INFO - \n",
      "backbone.layer3.22.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,187 - mmcv - INFO - \n",
      "backbone.layer3.22.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,189 - mmcv - INFO - \n",
      "backbone.layer3.22.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,189 - mmcv - INFO - \n",
      "backbone.layer3.22.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,190 - mmcv - INFO - \n",
      "backbone.layer3.22.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,190 - mmcv - INFO - \n",
      "backbone.layer3.22.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,190 - mmcv - INFO - \n",
      "backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,190 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,190 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,191 - mmcv - INFO - \n",
      "backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,191 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,191 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,191 - mmcv - INFO - \n",
      "backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,192 - mmcv - INFO - \n",
      "backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,192 - mmcv - INFO - \n",
      "backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,192 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,192 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,193 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,193 - mmcv - INFO - \n",
      "backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,193 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,193 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,194 - mmcv - INFO - \n",
      "backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,194 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,194 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,194 - mmcv - INFO - \n",
      "backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,194 - mmcv - INFO - \n",
      "backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,195 - mmcv - INFO - \n",
      "backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,195 - mmcv - INFO - \n",
      "backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,195 - mmcv - INFO - \n",
      "backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,195 - mmcv - INFO - \n",
      "backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,196 - mmcv - INFO - \n",
      "backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,196 - mmcv - INFO - \n",
      "backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,198 - mmcv - INFO - \n",
      "backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,198 - mmcv - INFO - \n",
      "backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,199 - mmcv - INFO - \n",
      "backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,199 - mmcv - INFO - \n",
      "backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet101 \n",
      " \n",
      "2025-09-22 21:10:43,199 - mmcv - INFO - \n",
      "neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,199 - mmcv - INFO - \n",
      "neck.lateral_convs.0.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
      " \n",
      "2025-09-22 21:10:43,200 - mmcv - INFO - \n",
      "neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,200 - mmcv - INFO - \n",
      "neck.lateral_convs.1.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
      " \n",
      "2025-09-22 21:10:43,200 - mmcv - INFO - \n",
      "neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,201 - mmcv - INFO - \n",
      "neck.lateral_convs.2.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
      " \n",
      "2025-09-22 21:10:43,201 - mmcv - INFO - \n",
      "neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,201 - mmcv - INFO - \n",
      "neck.lateral_convs.3.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
      " \n",
      "2025-09-22 21:10:43,202 - mmcv - INFO - \n",
      "neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,202 - mmcv - INFO - \n",
      "neck.fpn_convs.0.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 21:10:43,202 - mmcv - INFO - \n",
      "neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,202 - mmcv - INFO - \n",
      "neck.fpn_convs.1.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
      " \n",
      "2025-09-22 21:10:43,203 - mmcv - INFO - \n",
      "neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,203 - mmcv - INFO - \n",
      "neck.fpn_convs.2.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
      " \n",
      "2025-09-22 21:10:43,203 - mmcv - INFO - \n",
      "neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,203 - mmcv - INFO - \n",
      "neck.fpn_convs.3.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
      " \n",
      "2025-09-22 21:10:43,203 - mmcv - INFO - \n",
      "rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,204 - mmcv - INFO - \n",
      "rpn_head.rpn_conv.bias - torch.Size([256]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,204 - mmcv - INFO - \n",
      "rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,204 - mmcv - INFO - \n",
      "rpn_head.rpn_cls.bias - torch.Size([3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,205 - mmcv - INFO - \n",
      "rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,205 - mmcv - INFO - \n",
      "rpn_head.rpn_reg.bias - torch.Size([12]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,205 - mmcv - INFO - \n",
      "roi_head.bbox_head.fc_cls.weight - torch.Size([2, 1024]): \n",
      "XavierInit: gain=1, distribution=normal, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,205 - mmcv - INFO - \n",
      "roi_head.bbox_head.fc_cls.bias - torch.Size([2]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,205 - mmcv - INFO - \n",
      "roi_head.bbox_head.fc_reg.weight - torch.Size([4, 1024]): \n",
      "XavierInit: gain=1, distribution=normal, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,206 - mmcv - INFO - \n",
      "roi_head.bbox_head.fc_reg.bias - torch.Size([4]): \n",
      "NormalInit: mean=0, std=0.001, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,206 - mmcv - INFO - \n",
      "roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \n",
      "XavierInit: gain=1, distribution=normal, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,206 - mmcv - INFO - \n",
      "roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): \n",
      "XavierInit: gain=1, distribution=normal, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,206 - mmcv - INFO - \n",
      "roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): \n",
      "XavierInit: gain=1, distribution=normal, bias=0 \n",
      " \n",
      "2025-09-22 21:10:43,207 - mmcv - INFO - \n",
      "roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): \n",
      "XavierInit: gain=1, distribution=normal, bias=0 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "checkpoint_and_model = model_from_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2efb6448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<module 'icevision.models.mmdet.models.faster_rcnn' from '/home/aarlova/anaconda3/envs/ovarian_fastai/lib/python3.9/site-packages/icevision/models/mmdet/models/faster_rcnn/__init__.py'>,\n",
       " <icevision.models.mmdet.models.faster_rcnn.backbones.resnet_fpn.MMDetFasterRCNNBackboneConfig at 0x7ff55e9db250>,\n",
       " <ClassMap: {'background': 0, 'Follicle': 1}>,\n",
       " 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type = checkpoint_and_model[\"model_type\"]\n",
    "backbone = checkpoint_and_model[\"backbone\"]\n",
    "class_map = checkpoint_and_model[\"class_map\"]\n",
    "img_size = checkpoint_and_model[\"img_size\"]\n",
    "\n",
    "model_type, backbone, class_map, img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a687cb9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet101'}\n",
       "  (neck): FPN(\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (3): ConvModule(\n",
       "        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (3): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
       "  (rpn_head): RPNHead(\n",
       "    (loss_cls): CrossEntropyLoss()\n",
       "    (loss_bbox): L1Loss()\n",
       "    (rpn_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (rpn_cls): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (rpn_reg): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
       "  (roi_head): StandardRoIHead(\n",
       "    (bbox_roi_extractor): SingleRoIExtractor(\n",
       "      (roi_layers): ModuleList(\n",
       "        (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "        (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "        (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "        (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "      )\n",
       "    )\n",
       "    (bbox_head): Shared2FCBBoxHead(\n",
       "      (loss_cls): CrossEntropyLoss()\n",
       "      (loss_bbox): L1Loss()\n",
       "      (fc_cls): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (fc_reg): Linear(in_features=1024, out_features=4, bias=True)\n",
       "      (shared_convs): ModuleList()\n",
       "      (shared_fcs): ModuleList(\n",
       "        (0): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "        (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (cls_convs): ModuleList()\n",
       "      (cls_fcs): ModuleList()\n",
       "      (reg_convs): ModuleList()\n",
       "      (reg_fcs): ModuleList()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model object\n",
    "# The model is automatically set in the evaluation mode\n",
    "model = checkpoint_and_model[\"model\"]\n",
    "model.to(torch.device(\"cuda:2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c832d6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 <icevision.tfms.albumentations.albumentations_adapter.Adapter object at 0x7ff55a9e1ee0>\n"
     ]
    }
   ],
   "source": [
    "# Transforms\n",
    "size = img_size\n",
    "\n",
    "valid_tfms = tfms.A.Adapter([tfms.A.Resize(size, size), tfms.A.Normalize()])\n",
    "print(img_size, valid_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2ed2322-2e83-414f-b035-c8631d9cbd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = ClassMap(['Follicle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeae9be-cbf5-45d2-8e98-2bd2f6ca4aae",
   "metadata": {},
   "source": [
    "### <font size=\"5\">Load image processing modules</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd036ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openslide\n",
    "import cv2\n",
    "from skimage import morphology\n",
    "import cv2 as cv\n",
    "from shapely.geometry import Polygon, MultiPolygon, box\n",
    "from shapely.ops import unary_union\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from shapely.strtree import STRtree\n",
    "from shapely.geometry import mapping\n",
    "from pathlib import Path\n",
    "\n",
    "import geojson\n",
    "\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 50 # for high resolution figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59a4106d-8121-4b53-8c9a-0460daf3162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from skimage.morphology import disk\n",
    "from skimage import morphology\n",
    "import numpy as np\n",
    "\n",
    "def simple_get_mask(img):\n",
    "    gray = cv.cvtColor(np.asarray(img), cv.COLOR_RGB2GRAY)\n",
    "    _, mask = cv.threshold(gray, 0, 255, cv.THRESH_OTSU) # threshold using the OTSU method\n",
    "    mask = morphology.remove_small_objects(mask == 0, min_size=200, connectivity=2)\n",
    "    mask = morphology.remove_small_holes(mask, area_threshold=100)\n",
    "    mask = morphology.binary_dilation(mask, morphology.disk(1))\n",
    "    return mask\n",
    "\n",
    "# check for artifacts of slide scanning (horizontal or vertical thin dark strips)\n",
    "def is_artifact(minx, miny, maxx, maxy):\n",
    "    x_to_y = (maxx-minx)/(maxy-miny)\n",
    "    y_to_x = (maxy-miny)/(maxx-minx)\n",
    "    # print('x_to_y ratio:', int(x_to_y), ', y_to_x ratio:', int(y_to_x))\n",
    "    if x_to_y > 30 or y_to_x > 30:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# translate thumbnail-relative coords of Polygon to WSI-relative coords\n",
    "def translate_coords(polys, thumbnail_downsample_factor):\n",
    "    regions = []\n",
    "    if polys.type == 'MultiPolygon':\n",
    "        for i in range(len(polys.geoms)):\n",
    "            new_ext_x = np.array(polys.geoms[i].exterior.coords.xy[0])*thumbnail_downsample_factor\n",
    "            new_ext_y = np.array(polys.geoms[i].exterior.coords.xy[1])*thumbnail_downsample_factor\n",
    "            new_coords = list(zip(new_ext_x, new_ext_y))\n",
    "            regions.append(new_coords)\n",
    "    if polys.type == 'Polygon':\n",
    "        new_ext_x = np.array(polys.exterior.coords.xy[0]) * thumbnail_downsample_factor\n",
    "        new_ext_y = np.array(polys.exterior.coords.xy[1]) * thumbnail_downsample_factor\n",
    "        new_coords = list(zip(new_ext_x, new_ext_y))\n",
    "        regions.append(new_coords)\n",
    "\n",
    "    return regions\n",
    "\n",
    "def get_tissue_regions(mask, thumbnail_downsample_factor):\n",
    "    wsi_thumb_mask = mask.astype(np.uint8)\n",
    "\n",
    "    contours, hierarchy = cv.findContours(wsi_thumb_mask, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    contours = [np.squeeze(i) for i in contours]  # removing redundant dimensions\n",
    "    tissue_regions = [Polygon(i) for i in contours]\n",
    "\n",
    "    tissue_regions = unary_union(tissue_regions)\n",
    "\n",
    "    if tissue_regions.type == 'MultiPolygon':\n",
    "        no_artifacts = MultiPolygon([geom for geom in tissue_regions.geoms if is_artifact(*geom.bounds) == False])\n",
    "        tissue_regions = no_artifacts\n",
    "\n",
    "    print('done cleaning')\n",
    "\n",
    "    # visualize the resulting tissue_regions\n",
    "    fig, axs = plt.subplots()\n",
    "    axs.set_aspect('equal', 'datalim')\n",
    "    axs.invert_yaxis()\n",
    "\n",
    "    if tissue_regions.type == 'MultiPolygon':\n",
    "        for geom in tissue_regions.geoms:\n",
    "            xs, ys = geom.exterior.xy\n",
    "            axs.plot(xs, ys, color='b', linestyle='-', linewidth=0.3)\n",
    "    else:\n",
    "        # for geom in tissue_regions:\n",
    "        xs, ys = tissue_regions.exterior.xy\n",
    "        axs.plot(xs, ys, color='b', linestyle='-', linewidth=0.3)\n",
    "\n",
    "    plt.show()\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "    translated_tissue_regions = translate_coords(tissue_regions, thumbnail_downsample_factor) # These are sections of tissue on the slide\n",
    "\n",
    "    print('done translating')\n",
    "\n",
    "    return translated_tissue_regions\n",
    "\n",
    "\n",
    "def get_grid(polys, tile_size, ol, plot = False):\n",
    "    slide_patches = []\n",
    "    for i in range(len(polys)):\n",
    "        margin_poly = Polygon(polys[i])\n",
    "        minx, miny, maxx, maxy = margin_poly.bounds\n",
    "        minx, miny, maxx, maxy = int(minx), int(miny), int(maxx), int(maxy)\n",
    "\n",
    "        n_cols = int(np.ceil((maxx - minx) / (tile_size - ol)))\n",
    "        n_rows = int(np.ceil((maxy - miny) / (tile_size - ol)))\n",
    "\n",
    "        # all x's\n",
    "        x_zero = int(margin_poly.bounds[0])\n",
    "        xs = []\n",
    "        xs.append(x_zero)\n",
    "        for x in range(n_cols - 1):\n",
    "            next_x = x_zero + (tile_size - ol)\n",
    "            xs.append(next_x)\n",
    "            x_zero = next_x\n",
    "\n",
    "        # all y's\n",
    "        y_zero = int(margin_poly.bounds[1])\n",
    "        ys = []\n",
    "        ys.append(y_zero)\n",
    "        for y in range(n_rows - 1):\n",
    "            next_y = y_zero + (tile_size - ol)\n",
    "            ys.append(next_y)\n",
    "            y_zero = next_y\n",
    "\n",
    "        # assemble into rectangles\n",
    "        patches = []\n",
    "        for w in range(n_cols):\n",
    "            x = xs[w]\n",
    "            for z in range(n_rows):\n",
    "                y = ys[z]\n",
    "                rect = box(x, y, x + tile_size, y + tile_size, ccw=False)\n",
    "                patches.append(rect)\n",
    "\n",
    "        # find patches that intersect with tissue margin\n",
    "        tree = STRtree(patches)\n",
    "        query_geom = margin_poly\n",
    "        intersects = [n for n in tree.query(query_geom) if n.intersects(query_geom) and n.intersection(query_geom).area/n.area > 0.05]\n",
    "\n",
    "        # print('number of patches in this section: ', len(intersects))\n",
    "\n",
    "        # append intersecting patches to slide_patches list\n",
    "        slide_patches.append(intersects)\n",
    "\n",
    "        if plot == True:\n",
    "            # let's plot the intersecting ones\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "            # plot main_poly\n",
    "            ab = margin_poly.exterior.xy\n",
    "            a, b = np.array(ab[0]), np.array(ab[1])\n",
    "            ax.plot(a, b, color='b', linestyle='-', linewidth=0.4)\n",
    "            ax.invert_yaxis()\n",
    "\n",
    "            # plot other_polies\n",
    "            patches = intersects\n",
    "            color = ['r', 'g', 'b', 'c', 'y', 'm']\n",
    "            for j in range(len(patches)):\n",
    "                x, y = np.array(patches[j].exterior.xy[0]), np.array(patches[j].exterior.xy[1])\n",
    "                plt.plot(x, y, color=color[random.randint(0, 5)], linestyle='-', linewidth=0.4)\n",
    "            ax.grid(linestyle='--', linewidth='0.5')\n",
    "            plt.title(\"Finding Intersecting Polys\")\n",
    "            plt.xlabel(\"X\")\n",
    "            plt.ylabel(\"Y\")\n",
    "            plt.axis('equal')\n",
    "            plt.show()\n",
    "            plt.cla()\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n",
    "    return slide_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9391727-d78c-4be6-9a50-e86fbbde00a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_qupath_noIDs_Polys(xmlsave, regions, region_labels, region_colors):\n",
    "    dumped = []\n",
    "    trythis = '['\n",
    "    for i in range(0, len(regions)):\n",
    "        # if len(regions[i]) >2:\n",
    "            # roi = Polygon(regions[i])\n",
    "        roi = regions[i]\n",
    "        label = region_labels[i]\n",
    "        trythis += json.dumps(\n",
    "            {\"type\": \"Feature\", \"id\": \"PathAnnotationObject\", \"geometry\": mapping(roi),\n",
    "             \"properties\": {\"classification\": {\"name\": label, \"colorRGB\": region_colors}, \"isLocked\": False,\n",
    "                            \"measurements\": []}}, indent=4)\n",
    "        if i < len(regions) - 1:\n",
    "            trythis += ','\n",
    "        else:\n",
    "            dumped.append([region_labels[i], regions[i]])\n",
    "    trythis += ']'\n",
    "\n",
    "    with open(xmlsave, 'w') as outfile:\n",
    "        outfile.write(trythis)\n",
    "        \n",
    "        dumped = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "721e1048-d75b-464d-bf40-521147e90f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_geojson(jsonpath):\n",
    "    with open(jsonpath) as f:\n",
    "        allobjects = geojson.load(f)\n",
    "\n",
    "    #allshapes = [shape(obj[\"geometry\"]) for obj in allobjects]\n",
    "    allfeatures = allobjects['features']\n",
    "    allshapes = [obj[\"geometry\"]['coordinates'] for obj in allfeatures]\n",
    "    alllabels = [obj['properties'] for obj in allfeatures]\n",
    "    roilabels = list()\n",
    "    for roi_num in range(0, len(alllabels)):\n",
    "        roi_label = alllabels[roi_num]['classification']['name']\n",
    "        roilabels.append(roi_label)\n",
    "    \n",
    "    return allshapes, roilabels\n",
    "\n",
    "def read_geojson_nolabel(jsonpath):\n",
    "    with open(jsonpath) as f:\n",
    "        allobjects = geojson.load(f)\n",
    "\n",
    "    #allshapes = [shape(obj[\"geometry\"]) for obj in allobjects]\n",
    "    allfeatures = allobjects['features']\n",
    "    allshapes = [obj[\"geometry\"]['coordinates'] for obj in allfeatures]\n",
    "    alllabels = [obj['properties'] for obj in allfeatures]\n",
    "    \n",
    "    return allshapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1253dfe9-1cd8-46d9-884d-8468603a9ec9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <font size=\"5\"> Open Slides and Run Inference! </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dcf3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "requested_magn = 10\n",
    "downsample = int(40/requested_magn) # Use 4 for 10x, 2 for 20x, 1 for 40x\n",
    "tile_size = int(500*downsample) # Use 2000 for 10x, 1000 for 20x, 500 for 40x\n",
    "overlap = int(250*downsample)\n",
    "region_colors = -16274801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfa85560-8ac8-4eda-9aa6-7a2a549d1ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Slide  0   /media/14TB/aarlova_ovarian/SH_demo/input/17133893.svs\n",
      "opened slide!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 320x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done cleaning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 320x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done translating\n",
      "Set tile size to 2000 , and overlap to 1000\n",
      "Done tiling the slide!\n",
      "Number of sections in slide: 19\n",
      "Number of tiles in current section: 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aarlova/anaconda3/envs/ovarian_fastai/lib/python3.9/site-packages/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/home/aarlova/anaconda3/envs/ovarian_fastai/lib/python3.9/site-packages/mmdet/core/anchor/anchor_generator.py:360: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done processing tiles in section 0\n",
      "Number of tiles in current section: 73\n",
      "done processing tiles in section 1\n",
      "Number of tiles in current section: 61\n",
      "done processing tiles in section 2\n",
      "Number of tiles in current section: 11\n",
      "done processing tiles in section 3\n",
      "Number of tiles in current section: 192\n",
      "done processing tiles in section 4\n",
      "Number of tiles in current section: 58\n",
      "done processing tiles in section 5\n",
      "Number of tiles in current section: 203\n",
      "done processing tiles in section 6\n",
      "Number of tiles in current section: 77\n",
      "done processing tiles in section 7\n",
      "Number of tiles in current section: 62\n",
      "done processing tiles in section 8\n",
      "Number of tiles in current section: 189\n",
      "done processing tiles in section 9\n",
      "Number of tiles in current section: 76\n",
      "done processing tiles in section 10\n",
      "Number of tiles in current section: 64\n",
      "done processing tiles in section 11\n",
      "Number of tiles in current section: 8\n",
      "done processing tiles in section 12\n",
      "Number of tiles in current section: 76\n",
      "done processing tiles in section 13\n",
      "Number of tiles in current section: 11\n",
      "done processing tiles in section 14\n",
      "Number of tiles in current section: 191\n",
      "done processing tiles in section 15\n",
      "Number of tiles in current section: 75\n",
      "done processing tiles in section 16\n",
      "Number of tiles in current section: 63\n",
      "done processing tiles in section 17\n",
      "Number of tiles in current section: 12\n",
      "done processing tiles in section 18\n",
      "done with all sections\n",
      "Detected  4933 raw bboxes on slide!\n",
      "Len of unique preds on slide 1419\n",
      "Done saving JSON!\n"
     ]
    }
   ],
   "source": [
    "failed = []\n",
    "for i in range(len(slide_list)):\n",
    "\n",
    "\n",
    "    slide_fname = Path(slide_dir + '/' + slide_list[i] + '.svs')\n",
    "    print('Working on Slide ', i, ' ', slide_fname)\n",
    "\n",
    "    slide = openslide.OpenSlide(str(slide_fname))\n",
    "    print('opened slide!')\n",
    "    levels = int(slide.level_count)\n",
    "    thumb_dim = slide.level_dimensions[levels - 1]  # highest level corresponds to smallest available dimension\n",
    "    thumbnail_downsample_factor = int(slide.level_downsamples[levels - 1])  # corresponding downsample factor of the thumbnail to be produced\n",
    "\n",
    "    wsi_thumb = slide.get_thumbnail(thumb_dim)\n",
    "    plt.imshow(wsi_thumb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "    wsi_thumbnail_mask = simple_get_mask(wsi_thumb)\n",
    "\n",
    "    tissue_regions = get_tissue_regions(wsi_thumbnail_mask, thumbnail_downsample_factor)\n",
    "\n",
    "\n",
    "    # jsons_fname = Path('/media/14TB/aarlova_ovarian/margin_jsons_for_NIH/' + slide_list[i] + '.geojson')\n",
    "    # coords = read_geojson_nolabel(jsons_fname)\n",
    "    # tissue_regions = [Polygon(i[0]) for i in coords]\n",
    "\n",
    "    # coords, labels = read_geojson(jsons_fname)\n",
    "    # tissue_regions = [Polygon(i[0]) for i in coords]\n",
    "\n",
    "\n",
    "    #######################################################################\n",
    "    # generate a grid of tiles of specific size and overlap within bounds of the Ovary\n",
    "    print('Set tile size to', tile_size, ', and overlap to', overlap)\n",
    "    slide_grid = get_grid(tissue_regions, tile_size, overlap, plot=False) # slide_grid is a nested list of Polygons. Len(slide_grid) is how many sections of tissue are on slide.\n",
    "    print('Done tiling the slide!')\n",
    "\n",
    "    #######################################################################\n",
    "    # tile the slide with my script, get slide_grid\n",
    "    print('Number of sections in slide:', len(slide_grid))\n",
    "\n",
    "    slide_boxes = []\n",
    "\n",
    "    for section in range(len(slide_grid)):\n",
    "        print('Number of tiles in current section:', len(slide_grid[section]))\n",
    "\n",
    "\n",
    "        for tile in range(len(slide_grid[section])):\n",
    "            current_tile = slide_grid[section][tile]\n",
    "            current_tile_top_left_coord = [int(current_tile.bounds[0]), int(current_tile.bounds[1])]  # this should be minx, miny if polygons were created with ccw=False\n",
    "            # tile_name = str(out_tile_dir/slide_fname.stem) + '/' + str(slide_fname.stem) + ' [x=' + str(current_tile_top_left_coord[0]) + ',y=' + str(current_tile_top_left_coord[1]) + ',w='+str(tile_size) + ',h=' + str(tile_size) + '].jpg'\n",
    "            tile_img = slide.read_region((current_tile_top_left_coord[0], current_tile_top_left_coord[1]),0,(tile_size,tile_size)).convert('RGB')\n",
    "            resized_tile = tile_img.resize((500,500)) \n",
    "\n",
    "\n",
    "            #2. Predict on one individual tile at a time\n",
    "            pred_dict  = model_type.end2end_detect(resized_tile, valid_tfms, model, class_map=class_map, detection_threshold=0.25)\n",
    "            # pred_dict['img'].show()\n",
    "\n",
    "            poly_boxes = []\n",
    "\n",
    "            a = pred_dict['detection']['bboxes']\n",
    "            if len(a) > 0:\n",
    "                for b in a:\n",
    "                    poly = box(b.xmin, b.ymin, b.xmax, b.ymax)\n",
    "                    poly_boxes.append(poly)\n",
    "\n",
    "\n",
    "\n",
    "            #3. Translate tile-relative coords of Polygon to WSI-relative coords\n",
    "            for p in range(len(poly_boxes)):\n",
    "                new_ext_x = np.array(poly_boxes[p].exterior.coords.xy[0]) * downsample + current_tile_top_left_coord[0]\n",
    "                new_ext_y = np.array(poly_boxes[p].exterior.coords.xy[1]) * downsample + current_tile_top_left_coord[1]\n",
    "\n",
    "                new_coords = list(zip(new_ext_x, new_ext_y))\n",
    "                new_poly = Polygon(new_coords)\n",
    "                slide_boxes.append(new_poly)\n",
    "\n",
    "\n",
    "            tile_img.close()\n",
    "            resized_tile.close()\n",
    "\n",
    "\n",
    "\n",
    "        print('done processing tiles in section', section)\n",
    "\n",
    "\n",
    "\n",
    "    print('done with all sections')\n",
    "\n",
    "    slide.close()\n",
    "\n",
    "    print('Detected ', len(slide_boxes), 'raw bboxes on slide!')\n",
    "\n",
    "\n",
    "    ########### Make JSONs ###########\n",
    "    ########### filter out 'too' rectangular polygons\n",
    "    filtered = []\n",
    "    for o in slide_boxes:\n",
    "        x = o.bounds[2] - o.bounds[0]\n",
    "        y = o.bounds[3] - o.bounds[1]\n",
    "\n",
    "        abs_log_aspect_ratio_sample = abs(math.log(x/(y+0.000000001)))\n",
    "\n",
    "        if abs_log_aspect_ratio_sample <= 0.5:\n",
    "            filtered.append(o)\n",
    "    # print('After filtered by aspect ratio', len(filtered))\n",
    "\n",
    "\n",
    "    ########## remove intersecting whose intersection with other is greater than 50% of its area?\n",
    "    tree = STRtree(filtered)\n",
    "\n",
    "    all_merged = []\n",
    "    for i in filtered:\n",
    "        query_geom = i\n",
    "        # intersects = [o for o in tree.query(query_geom) \n",
    "        #               if o.intersection(query_geom).area/unary_union([o,query_geom]).area > 0.5]\n",
    "        intersects = [o for o in tree.query(query_geom) if o.intersection(query_geom).area/o.area > 0.5]\n",
    "\n",
    "        merged = unary_union(intersects)\n",
    "        all_merged.append(merged)\n",
    "\n",
    "    # print('After merging intersecting polygons', len(all_merged))\n",
    "\n",
    "    ############### remove duplicates from all_merged:\n",
    "    all_merged_coords = [f.bounds for f in all_merged] # convert to list of coords in order to find unique polygons\n",
    "    unique_merged = set(all_merged_coords)\n",
    "    # print('Len of unique merged polygons after removing duplicates',len(unique_merged))\n",
    "    unique_merged = [box(*u) for u in unique_merged] # back to Polygons\n",
    "\n",
    "    ############### remove polygons that are covered by other polygons\n",
    "    tree = STRtree(unique_merged)\n",
    "    to_remove = []\n",
    "    for i in unique_merged:\n",
    "        query_geom = i\n",
    "        covered_by = [o for o in tree.query(query_geom) if o.covered_by(query_geom) and not o.equals(query_geom)]\n",
    "        to_remove.extend(covered_by) # list of polygons to remove\n",
    "\n",
    "    ############### remove duplicates\n",
    "    all_merged_coords = [f.bounds for f in unique_merged]\n",
    "    to_remove_coords = [f.bounds for f in to_remove]\n",
    "    unique_merged = set(all_merged_coords) - set(to_remove_coords)\n",
    "    unique_merged = [box(*u) for u in unique_merged] # back to Polygons\n",
    "    print('Len of unique preds on slide',len(unique_merged))\n",
    "\n",
    "    ############## write JSON files\n",
    "    slide_follicles = unique_merged\n",
    "    slide_labels = ['Follicle' for f in slide_follicles]\n",
    "\n",
    "    write_qupath_noIDs_Polys(str(json_dir) + '/' + str(slide_fname.stem) + '_fastRCNN.json', slide_follicles, slide_labels, region_colors)\n",
    "    print('Done saving JSON!')\n",
    "    # except:\n",
    "    #     failed.append(slide_fname)\n",
    "\n",
    "    # write all original preds\n",
    "    # slide_labels = ['Follicle' for f in slide_boxes]\n",
    "    # write_qupath_noIDs_Polys(str(json_dir) + '/' + str(slide_fname.stem) + '_fastRCNN_all.json', slide_boxes, slide_labels, region_colors)\n",
    "\n",
    "# print('Failed to Infer with Object Detection', len(failed), failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c451ece-c2ad-4f7a-a596-653745b0ee5d",
   "metadata": {},
   "source": [
    "### <font size=\"5\">Visualize predictions (not required!)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f11c30c-0d97-4d93-9570-c7cfc7dc615e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 320x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# plot slide_boxes\n",
    "patches = slide_follicles\n",
    "color = ['r', 'g', 'b', 'c', 'y', 'm']\n",
    "for j in range(len(patches)):\n",
    "    x, y = np.array(patches[j].exterior.xy[0]), np.array(patches[j].exterior.xy[1])\n",
    "    plt.plot(x, y, color=color[random.randint(0, 5)], linestyle='-', linewidth=0.4)\n",
    "ax.grid(linestyle='--', linewidth='0.5')\n",
    "plt.title(\"Slide Detections\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b6213-a075-4a30-aa35-f1837c712837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
